 ---
output: pdf_document
---

\begin{quote}
\emph{Exploring the unknown requires tolerating uncertainty.}
--- Brian Greene
\end{quote}


\doublespacing

# Introduction

The results of both Phase I (the development of the method and its software) and Phase II (the Monte Carlo simulations) regarding Marginal Mediation Analysis (MMA) are presented in this chapter.

# Developmental Considerations

The general MMA framework was discussed in Chapter 3. This framework was extended with some important additional considerations, including integrating moderation and analytically assessing the relation between the decomposed total effect and the total effect.

## Moderation

Moderation (interaction) is sometimes hypothesized to occur in conjunction with mediation. Moderation is any situation where the effect of a variable on another *depends* on the value of a third variable. This phenomenon, in conjunction with mediation, is often referred to as conditional process analysis, moderated mediation, or mediated moderation---depending on the source and situation. 

An example of one of the many possible moderated mediation models is found in Figure \ref{fig:modmed} [for more examples, see @Hayes2013book]. In this example, the moderator (denoted W in the figure), moderates that relationship between X and M. In other words, the effect of X on M depends on the value of W. This further suggests that the effect of X on Y, through M, also depends on the value of W.

\begin{figure}[tb]
\centering
\includegraphics[width = \linewidth]{figures/fig_mod_med.pdf}
\caption{An example of moderated mediation, where the moderator (denoted W), moderates the effect of X on M (the a path).}
\label{fig:modmed}
\end{figure}

In general, interactions make interpretation more difficult. In linear models, the interpretation of the interaction estimate becomes: "a one unit increase in X is associated with a $\beta_x + \beta_{int} \times W$ effect on the outcome." That is, to understand the size, and direction, of the effect of X, the level of W must be considered. For example, if W is a categorical variable with values of 0 and 1, and the following regression was estimated:

\begin{equation}
\hat{M}_i = 1.0 + 5.0 X + 3.0 W + .5 X*W
\end{equation}

\noindent then:

1. X is associated with a 5.0 increase in M when W is 0, and
2. X is associated with a 5.5 increase in M when W is 1.

\noindent The same logic holds for continuous moderators, although representative values of W must be chosen instead of using all possible values.

Yet, in non-linear situations, this becomes more strenuous. However, using average marginal effects, the interpretation can be like that of linear models. In general, this has been done by selecting various, representative values of W at which the average marginal effect is assessed [@Stata14]. If W is categorical then all observed values can be used. Notably, in linear and generalized linear models, moderation is probably best understood using visualizations---showing the effect of X at various levels of W (see Figure \ref{fig:interaction}).


```{r interaction_example, message = FALSE, warning=FALSE, eval=FALSE}
set.seed(843)
library(tidyverse)
tibble::data_frame(
  X = rnorm(100),
  W = rbinom(100, 1, .5),
  Y = X + .5*W + -.5*X*W + rnorm(100)
) %>%
  ggplot(aes(X, Y, group = factor(W), color = factor(W))) +
    geom_point(alpha = .3) +
    geom_smooth(method = "lm", se=FALSE) +
    scale_color_manual(values = c("dodgerblue4", "chartreuse4")) +
    labs(color = "Moderator") +
    anteo::theme_anteo_wh()
ggsave("figures/fig_interaction_effect.pdf", 
       width = 7, height = 5, units = "in")
```

\begin{figure}[tb]
\centering
\includegraphics[width = \linewidth]{figures/fig_interaction_effect.pdf}
\caption{An example of a common approach to visualizing a moderation effect where the effect of X on Y is shown for each level of W.}
\label{fig:interaction}
\end{figure}

In relation to MMA, moderation can be understood at both 1) an individual path level and 2) a complete model level. At an individual path level, moderation is understood as it is in non-mediating regression situations. For example, if path a is moderated, the effect of X on M can be understood via visualizations or representative values of W can be inserted into the regression equation, as in the example above.

To understand it in relation to the complete model, the framework discussed by Edwards and Lambert (2007) suggests using the *reduced form* of the mediation model to understand the moderation in the context of the indirect and direct effects. The reduced form refers to having only exogenous variables on the right-hand side of the equation (i.e., substituting the estimates of the a path into the b/c path model) as shown below.

Starting with the non-reduced form, we have $M_i$, an endogenous variable, on the right hand side. 
\begin{equation}
Y_i = \beta_0 + b_1 M_i + c^{`}_1 x_i + \epsilon_{yi}
\end{equation}
\noindent Using the a path model, and assuming the same model specification as in Figure \ref{fig:modmed}, we can substitute in the predictors of $M_i$.
\begin{equation}
Y_i = \beta_0 + b_1 (a_0 + a_1 x_i + a_2 w_i + a_3 x_i * w_i) + c^{'}_1 x_i + \epsilon_{yi}
\end{equation}
\noindent This form is now reduced so that only exogenous variables are on the right-hand side. Using these estimates, it is now possible to assess the effect of $x$ on $Y$ when it depends on the level of $w$ using the same approach with the individual paths. Importantly, using these estimates, the moderated effect of $x$ can be visualized as well.

## The Decomposed Total Effect Equals The Total Effect

When using the average marginal effect, the decomposed total effect ($a \times b + c'$) equals that of the original total effect ($c$). @Winship1983, demonstrated that, using calculus, an outcome variable Y can be decomposed by its total differential
\begin{equation}
dY = \frac{\delta Y}{\delta X}dX + \frac{\delta Y}{\delta M}dM
\end{equation}
\noindent which implies the general formula
\begin{equation}
\frac{dY}{dX} = \frac{\delta Y}{\delta X} + \frac{\delta Y}{\delta M}\frac{dM}{dX}
\end{equation}
\noindent (pg. 83, the symbols were altered to match that of the present project). That is, the total effect is equal to the direct plus indirect effects. If the average marginal effect is a good estimate of the derivative (or partial derivative), then:
\begin{equation}
\frac{dY}{dX} = \frac{\delta Y}{\delta X} + \frac{\delta Y}{\delta M}\frac{dM}{dX} = c' + b \times a = c
\end{equation}
\noindent Therefore, it is expected that regardless of the distributions of the mediators or outcomes $a \times b + c' = c$. 

This is further demonstrated with finite sampling properties in the Monte Carlo simulation in Phase II using both binary and count mediators.

# Standardized Effects

It is often of considerable worth to understand standardized effects. These can be defined in numerous ways, depending on the situation and types of variables that are being used. In situations where the outcome is continuous, MMA can use a partial standardization approach discussed by Preacher and Hayes (2011) where the outcome is standardized using its own standard deviation. This produces interpretations that are based on the change in the outcome in standard deviation units. If using a dichotomous predictor, this essentially becomes a standardized mean difference (e.g., Cohen's D). It is also possible to standardize both the continuous outcomes and continuous predictors to obtain a partial correlation metric from these models as well.

As discussed below, the software to perform MMA includes the outcome standardization for continuous outcomes but does not provide standardization techniques for the predictors. Future iterations of the software will include this as well.\footnote{The researcher can standardize the continuous predictors and outcomes before performing MMA, in which case they can obtain the partial correlation estimates with the current version of the software.}


# Software Development

The software package developed for MMA is called `MarginalMediation` and is freely available via the R statistical environment. The software allows straightforward use of MMA across continuous, binary, and count mediators and/or outcomes (other distributions also work but have not been extensively tested). The computation is done in several steps:

1. Function and model checks
2. $a$ path average marginal effect estimates
3. $b$ and $c'$ path average marginal effect estimates
4. Bootstrapped confidence intervals
5. Formatting and printing of the output

This strategy was undertaken to help in error-checking and allows the function to print informative output to the user during the modeling, which is especially useful for situations with large samples and many bootstrapped samples.

## Functions

Using the package is based on a single function---`mma()`---that provides the main functionality (Figure \ref{fig:mma}). `mma()` is built on several other functions that perform specific duties that allow the simple syntax. The main functions of the package are shown in Table \ref{tab_functions}.

\begin{figure}[tb]
\centering
\includegraphics[width = \linewidth]{figures/fig_mma_structure.pdf}
\caption{The structure of the \texttt{mma()} function. From left to right: (1) inputs inform the function of the model specifications, the indirect effects to be reported, and other arguments; (2) internal processes including checks/formatting and internal calculations, (3) the output with some truncated example output. Notably, the numbers along the solid arrows pointing at the \texttt{mma()} function show the order of the operations, namely checks, AMEs, indirect and direct effects, bootstrapped confidence intervals, and formatting of the output.}
\label{fig:mma}
\end{figure}


\begin{table}[tb] 
\centering 
\caption{Functions used in the \texttt{MarginalMediation} R package.}
\label{tab_functions}
\begin{tabular}{p{38mm}p{45mm}p{55mm}}
\toprule
Type                & Function         & Behavior   \\ 
\midrule
Main Function            & \verb|mma()|     & Performs the full MMA model  \\
Marginal Function        & \verb|amed()|    & Computes the average marginal effects of a given GLM model   \\ 
Moderated Mediation      & \verb|mod_med()| & Computes the marginal effects at various levels of a moderator (still in testing) \\
Checks and formatting    & These functions perform behind the scenes & Check model specification and function requirements  \\ 
Other Functions          & \verb|mma_std_ind_effects()| and \verb|mma_std_dir_effects()| & Obtain the standardized indirect and direct effects from the model \\
Other Functions          & \verb|mma_ind_effects()| and \verb|mma_dir_effects()| & Obtain the unstandardized indirect and direct effects from the model \\
Other Functions          & \verb|perc_med()| & Obtain the percent of mediation for each specified path in the model \\
\bottomrule
\end{tabular}
\end{table} 


## Computation of the Marginal Effect

`MarginalMediation` uses built-in R functionality that allows for relatively fast computation of the marginal effects. The approach taken here is identical to that of the `margins` R package [@Leeper2017], as described in Chapter 3. This is repeated here. Specifically, for continuous predictors, the numerical derivative is used as shown below where $a$ is the general symbol for the model estimates.
\begin{equation}
AME_k = \frac{1}{n} \sum_{i = 1}^n \frac{f(aX_1) - f(aX_2)}{2h}
\end{equation}
\noindent where 
\begin{equation}
aX_1 = \begin{bmatrix}
ax_{11} & ax_{12} & \dots & ax_{1k} + h & \dots & ax_{1p} \\
ax_{21} & ax_{22} & \dots & ax_{2k} + h & \dots & ax_{2p} \\
\vdots  & \vdots  & \ddots & \vdots     & \ddots  & \vdots \\
ax_{n1} & ax_{n2} & \dots & ax_{nk} + h & \dots & ax_{np}
\end{bmatrix}
\end{equation}
\noindent and
\begin{equation}
aX_2 = \begin{bmatrix}
ax_{11} & ax_{12} & \dots & ax_{1k} - h & \dots & ax_{1p} \\
ax_{21} & ax_{22} & \dots & ax_{2k} - h & \dots & ax_{2p} \\
\vdots  & \vdots  & \ddots & \vdots     & \ddots  & \vdots \\
ax_{n1} & ax_{n2} & \dots & ax_{nk} - h & \dots & ax_{np}
\end{bmatrix}
\end{equation}
\noindent With a small $h$ (default is $1 \times 10^{-7}$), this produces the average marginal effect across all the observations (e.g., the average change in the predicted value for a very small increase and a very small decrease in in the $x_k$ variable).

For discrete predictors, the discrete difference is used as shown below,
\begin{equation}
AME_{k} = \frac{1}{n} \sum_{i=1}^{n} \big[ F(\beta X | x_{ki} = 1) - F(\beta X | x_{ki} = 0) \big]
\end{equation}
\noindent where $F(\beta X | x_{ki} = 1)$ is the predicted value of the $ith$ observation when the dummy variable $x_k$ equals one and $F(\beta X | x_{ki} = 0)$ is the predicted value when the dummy value of $x_k$ equals zero holding all other variables constant. This, in effect, shows the discrete difference between the levels of the categorical variable in the outcome's original units.

These approaches are employed in `MarginalMediation` due to their flexibility across GLM types and model specifications. For example, it can handle many types of models (e.g., linear, GLM, multilevel) and can produce more interpretable estimates of the marginal effects of predictors that have quadratic terms (e.g., $age$ and $age^2$).

### Standardization

As was briefly noted earlier, partial standardization wherein the outcome is standardized is possible when the outcome is continuous. In these situations, the output of `MarginalMediation` will include both unstandardized and standardized effects (see Figure \ref{fig_mmaexample}).


## Examples of Software Use

To briefly demonstrate the use of `mma()`, fictitious data were first generated, where X, M, and Y are continuous. Using these data (called `df1`), the following `R` code demonstrates the use of `mma()` in the simplest case. 

```{r}
library(tidyverse)
df1 = data_frame(
  X = rnorm(100),
  M = X + rnorm(100),
  Y = M + X + rnorm(100)
)
```

\singlespacing
```{r, echo=TRUE, results='hide'}
library(MarginalMediation)

pathbc = glm(Y ~ X + M, data = df1)
patha  = glm(M ~ X, data = df1)

fit = mma(pathbc,
          patha,
          ind_effects = c("X-M"))
```
\doublespacing

First, the individual sub-models are fit thereby creating `pathbc` and `patha` which are both `glm` objects. Then, the b and c paths (`pathbc`) model object is the first argument to `mma()`, followed by the a paths (in this case only a single a path but multiple---separated by commas---can be included). The necessary argument is the `ind_effects`. This argument expects a vector or list of quoted paths, where the paths are the form `"predictor-mediator"`. In this case, the predictor is called `X` and the mediator is called `M`.

The `fit` object as created by `mma()` contains a number of elements, including the indirect effects, the direct effects, the confidence interval, and the original data. Figure \ref{fig_mmaexample} provides an example of how the output could look if the `fit` object is printed. This output provides both unstandardized effects (both indirect and direct) that are in the units of the outcome and standardized effects---using the standard deviation of the outcome as recommended by MacKinnon (2008)---which are in the standard deviation units of the outcome. 

\begin{figure}[tb]
\centering
\includegraphics[width = 0.5\textwidth]{figures/fig_mma_example.png}
\caption{An example of the output from the \texttt{mma()} function.}
\label{fig_mmaexample}
\end{figure}

```{r}
pathc = glm(Y ~ X, data = df1)
```

Further, it can be assessed whether, in this case, the indirect plus the direct effects equal the total effect. Here, the total effect is `r 0.885 + 1.036` which is equal to the indirect effect (`r 0.885`) plus the direct effect (`r 1.036`). This suggests that comparisons between the effects can be confidently made.

If a covariate, $X2$ is added to the data, this can be easily added to the model as shown below.

```{r}
df1$X2 = rnorm(100)
```

\singlespacing
```{r, echo=TRUE, results='hide'}
library(MarginalMediation)
pathbc = glm(Y ~ X + X2 + M, data = df1)
patha  = glm(M ~ X + X2, data = df1)

fit2 = mma(pathbc,
           patha,
           ind_effects = c("X-M",
                           "X2-M"))
```
\doublespacing

It is also possible to access various aspects of these MMA model fit objects.

```{r, echo=TRUE, eval=FALSE}
perc_med(fit2, "X-M")
```

\noindent This informs the researcher that the indirect effect accounts for approximately `r round(perc_med(fit2, "X-M"),0)`\% of the total effect from X to Y in `fit2`.

# Monte Carlo Simulation Study

With the software package `MarginalMediation`, the simulations were able to assess the package's functionality and the overall framework's ability to estimate the underlying effects accurately. First, to assess the appropriateness of the experimental conditions, a literature review was conducted.

## Literature Review

Studies were sought that saliently reported results wherein both mediation analysis and generalized linear models were used. Since 2012, this produced 57 articles (via Scopus).\footnote{The search terms included: "mediation analysis" and ["logistic" or "generalized linear models" or "GLM" or "poisson"].} Among these, three general categories of articles were found:

1. Articles that were methodologically building on mediation analysis.
2. Articles that applied mediation where a mediator and/or outcome was categorical and the authors used the "difference method" (MacKinnon, 2008) to assess the amount of mediation.
3. Articles that applied mediation where a mediator and/or outcome was categorical and the authors either used the structural equation modeling approach or did not include the categorical mediator and/or outcome in the mediation.

Of these, number two was most prevalent. The literature suggested that the parameters selected for the simulations were relevant, particularly the small effect sizes and large sample sizes. Most studies used extant, large questionnaire data sets and the majority were cross-sectional.

Importantly, this search demonstrated the commonality of the "difference method" as discussed by MacKinnon (2008). This method relies on the following:

\singlespacing
\begin{equation}
a \times b + c' = c
\end{equation}
\begin{equation}
a \times b = c - c'
\end{equation}
\doublespacing

\noindent In essence, this says that it is possible to estimate the indirect effect, that is $a \times b$ by assessing the difference $c - c'$. However, in situations where the decomposed total effect does not equal the total effect, this method may not be valid although many studies still used this approach in categorical data situations.


## Simulations

```{r sim_data_clean, eval=FALSE}
options(na.rm=TRUE)

library(tidyverse)
library(furniture)
library(here)

es = read.csv("effect_sizes.csv") %>%
  data.frame(row.names = .$size) %>%
  select(-size)

filenames = list.files(here("Sims_Data/"), 
                       pattern = ".rda")

tot = indc = indd = 
  dirc = dird = vector("list", length(filenames))
for (i in filenames){
  cat("File:", i, "\n")
  load(paste0(here("Sims_Data/", i)))
  
  tot[[i]] = lapply(out, function(x) x$Total) %>%
    do.call("rbind", .) %>%
    data.frame %>%
    mutate(type = strsplit(i, "_")) %>%
    mutate(ss   = map_chr(type, ~.x[2])) %>%
    mutate(dist = map_chr(type, ~.x[1])) %>%
    mutate(boot = map_chr(dist, ~ifelse(grepl("2$", .x), 500, 100))) %>%
    mutate(dist = map_chr(dist, ~gsub("2", "", .x))) %>%
    mutate(ap   = map_chr(type, ~.x[3])) %>%
    mutate(bp   = map_chr(type, ~.x[4])) %>%
    mutate(cp   = map_chr(type, ~gsub("\\.rda", "", .x[5]))) %>%
    select(Xc, ss, dist, boot, ap, bp, cp)
  indc[[i]] = lapply(out, function(x) x$IndEffects[1, ]) %>%
    do.call("rbind", .) %>%
    data.frame %>%
    mutate(type = gsub(".rda", "", i)) %>%
    mutate(type = strsplit(type, "_")) %>%
    mutate(ss   = map_chr(type, ~.x[2])) %>%
    mutate(dist = map_chr(type, ~.x[1])) %>%
    mutate(boot = map_chr(dist, ~ifelse(grepl("2$", .x), 500, 100))) %>%
    mutate(dist = map_chr(dist, ~gsub("2", "", .x))) %>%
    mutate(ap   = ifelse(dist == "Count", 
                         ifelse(map_chr(type, ~.x[3]) == "0.3", "Small",
                         ifelse(map_chr(type, ~.x[3]) == "0.6", "Mod", 
                                "Large")),
           
                         ifelse(map_chr(type, ~.x[3]) == "0.55", "Small",
                         ifelse(map_chr(type, ~.x[3]) == "1.45", "Mod", 
                                "Large")))) %>%
    mutate(bp   = ifelse(map_chr(type, ~.x[4]) == "0.24", "Small",
                  ifelse(map_chr(type, ~.x[4]) == "0.62", "Mod", 
                  ifelse(map_chr(type, ~.x[4]) == "1.068", "Large",
                  ifelse(map_chr(type, ~.x[4]) == "0.084", "Small",
                  ifelse(map_chr(type, ~.x[4]) == "0.265", "Mod", 
                         "Large")))))) %>%
    mutate(cp   = map_chr(type, ~.x[5])) %>%
    mutate(power = ifelse(Lower > 0 & Upper > 0, 1, 0)) %>%
    mutate(ind_cat = paste(ap, "x", bp)) %>%
    mutate(true  = ifelse(dist == "Count", 
                          es[ind_cat, "ind_count"],
                          es[ind_cat, "ind_binary"])) %>%
    mutate(ap_size = ifelse(dist == "Count", 
                            es[ind_cat, "a_count"],
                            es[ind_cat, "a_binary"])) %>%
    mutate(bp_size = ifelse(dist == "Count", 
                            es[ind_cat, "b_count"],
                            es[ind_cat, "b_binary"])) %>%
    mutate(ci    = ifelse(true < Upper & true > Lower, 1, 0)) %>%
    select(-type)
  dirc[[i]] = lapply(out, function(x) x$DirEffects[1, ]) %>%
    do.call("rbind", .) %>%
    data.frame %>%    
    mutate(type = gsub(".rda", "", i)) %>%
    mutate(type = strsplit(type, "_")) %>%
    mutate(ss   = map_chr(type, ~.x[2])) %>%
    mutate(dist = map_chr(type, ~.x[1])) %>%
    mutate(boot = map_chr(dist, ~ifelse(grepl("2$", .x), 500, 100))) %>%
    mutate(dist = map_chr(dist, ~gsub("2", "", .x))) %>%
    mutate(ap   = map_chr(type, ~.x[3])) %>%
    mutate(bp   = map_chr(type, ~.x[4])) %>%
    mutate(cp   = map_chr(type, ~.x[5])) %>%
    mutate(ci   = ifelse(Lower > 0 & Upper > 0 & cp > 0, 1, 
                  ifelse(Lower < 0 & Upper > 0 & cp == 0, 1, 0))) %>%
    mutate(power = ifelse(Lower > 0 & Upper > 0, 1, 0)) %>%
    mutate(true  = cp) %>%
    select(-type)
}

ind1 = do.call('rbind', indc) %>%
  mutate(var = "continuous") %>%
  select(Indirect, Lower, Upper, ss, dist, 
         boot, ap, bp, cp, ci, true, power, 
         var, ap_size, bp_size)
dir1 = do.call('rbind', dirc) %>%
  mutate(var = "continuous") %>%
  select(Direct, Lower, Upper, ss, dist, 
         boot, cp, ci, var, power)
tot1  = do.call('rbind', tot) %>%
  select(Xc, ss, dist, boot)
```

```{r total_fig, eval=FALSE}
## Total = Total
total_total = cbind(tot1[,1], ind1[1:45000,1], dir1[1:45000,1]) %>%
  data.frame %>%
  set_names(c("total", "indirect", "direct")) %>%
  mutate(sample = ind1[1:45000,"ss"]) %>%
  mutate(sample = factor(sample,
                         levels = c("50", "100", "200", "500", "1000"))) %>%
  mutate(ap   = ind1[1:45000,"ap"],
         bp   = ind1[1:45000,"bp"],
         dist = ind1[1:45000,"dist"],
         true = ind1[1:45000,"true"]) %>%
  mutate(true = as.numeric(as.character(true))) %>%
  mutate(diff = (total - (indirect + direct))) %>%
  mutate(est  = (total - (indirect + direct))/true) %>%
  mutate(eff  = paste(ap, "x", bp)) %>%
  group_by(sample, eff, dist) %>%
  mutate(index = 1:n())
p1tot = total_total %>%
  filter(dist == "Binary") %>%
  ggplot(aes(index, diff)) +
    geom_path() +
    scale_x_continuous(breaks = c(250, 500),
                       labels = c("250", "500")) +
    scale_y_continuous(breaks = c(-.1,0,.1)) +
    facet_grid(eff~sample) +
    anteo::theme_anteo_wh() +
    theme(panel.spacing = unit(.1, "cm"),
          strip.text.y = element_blank()) +
    labs(x = "Simulation Number",
         y = "Total - (Indirect + Direct)\n",
         subtitle = "a) Binary Condition")
p2tot = total_total %>%
  filter(dist == "Count") %>%
  ggplot(aes(index, diff)) +
  geom_path() +
  scale_x_continuous(breaks = c(250, 500),
                     labels = c("250", "500")) +
  scale_y_continuous(breaks = c(-2,0,2)) +
  coord_cartesian(ylim = c(-2.9,3.1)) +
  facet_grid(eff~sample) +
  anteo::theme_anteo_wh() +
  theme(panel.spacing = unit(.1, "cm")) +
  labs(x = "Simulation Number",
       y = "",
       subtitle = "b) Count Condition")

plot_total = gridExtra::grid.arrange(p1tot, p2tot, ncol = 2)
ggsave("figures/fig_total_total.pdf",
       plot = plot_total,
       width = 10, height = 10, units = "in")
```

```{r acc_power_cover, eval=FALSE}
## Accuracy, Power, Coverage
inds = ind1 %>% 
  mutate(accuracy = (as.numeric(Indirect) - 
                       (as.numeric(ap_size) * 
                          as.numeric(bp_size)))) %>%
  group_by(ss, dist, boot = as.numeric(boot), ap_size, 
           bp_size, cp, var, ap, bp) %>%
  summarize(Ind = mean(Indirect),
            Low = mean(Lower),
            Hi  = mean(Upper),
            ci  = mean(ci),
            power = mean(power),
            acc = mean(accuracy)) %>%
  ungroup
dirs = dir1 %>%
  group_by(ss, dist, boot = as.numeric(boot), cp, var) %>%
  summarize(Dir = mean(Direct),
            Low = mean(Lower),
            Hi  = mean(Upper),
            ci  = mean(ci),
            power = mean(power))

ggplot(inds, aes(x = as.numeric(ss), y = power, 
                 color = paste(ap, "x", bp), 
                 group = interaction(ap, bp, boot, dist, cp))) +
  geom_hline(yintercept = .8, color = "darkgrey") +
  geom_line(alpha = .8) +
  geom_point(alpha = .8) +
  facet_grid(~ dist, space = "free", scales = "free") +
  anteo::theme_anteo_wh() +
  theme(panel.spacing = unit(.25, "cm"),
        axis.line = element_line(color = "darkgrey"),
        legend.position = "none") +
  scale_y_continuous(breaks = c(0, .2, .4, .6, .8, 1),
                     labels = scales::percent) +
  labs(y = "Power",
       x = "Sample Size") +
  ggrepel::geom_text_repel(data = inds %>% 
              filter(ss == 50),
            aes(label = paste(ap, "x", bp)),
            nudge_x = -150) +
  coord_cartesian(xlim = c(-250, 1000),
                  ylim = c(0,1))
ggsave("figures/sim_fig_power.pdf", 
       width = 10, height = 6, units = "in")

ggplot(ind1, aes(x = Indirect, fill = dist, 
                 color = dist, 
                 group = interaction(ap, bp, boot, dist, cp))) +
  geom_density(alpha = .5) +
  geom_vline(aes(xintercept = true, color = dist)) +
  facet_wrap(~ paste(ap, "x", bp), scales = "free") +
  anteo::theme_anteo_wh() +
  theme(panel.spacing = unit(.25, "cm"),
        axis.line = element_line(color = "darkgrey"),
        legend.position = "bottom") +
  labs(y = "Density",
       x = "Estimated and True Effect Size",
       fill = "Mediator Distribution",
       color = "Mediator Distribution") +
  scale_fill_manual(values = c("dodgerblue4", "coral2")) +
  scale_color_manual(values = c("dodgerblue4", "coral2"))
ggsave("figures/sim_fig_acc.pdf", 
       width = 8, height = 6, units = "in")

p1 = ggplot(inds, aes(x = as.numeric(ss), y = ci, 
                      color = paste(ap, "x", bp), 
                      group = interaction(ap, bp, boot, dist, cp))) +
  geom_hline(alpha = .8, yintercept = .95, color = "darkgrey") +
  geom_line(alpha = .8) +
  geom_point(alpha = .8) +
  facet_grid(~ dist, space = "free", scales = "free") +
  anteo::theme_anteo_wh() +
  theme(panel.spacing = unit(.25, "cm"),
        axis.line = element_line(color = "darkgrey"),
        legend.position = "none") +
  labs(y = "CI Coverage",
       x = "Sample Size",
       subtitle = "a) Overall Coverage") +
  coord_cartesian(ylim = c(0,1))
p2 = ggplot(inds, aes(x = as.numeric(ss), y = ci, 
                      color = paste(ap, "x", bp), 
                      group = interaction(ap, bp, boot, dist, cp))) +
  geom_hline(alpha = .8, yintercept = .95, color = "darkgrey") +
  geom_line(alpha = .8) +
  geom_point(alpha = .8) +
  facet_grid( ~ dist, space = "free", scales = "free") +
  anteo::theme_anteo_wh() +
  theme(panel.spacing = unit(.25, "cm"),
        axis.line = element_line(color = "darkgrey"),
        legend.position = "none") +
  labs(y = "CI Coverage",
       x = "Sample Size",
       subtitle = "b) Closer View of the Overall Coverage") +
  ggrepel::geom_text_repel(data = inds %>% 
                             filter(ss == 1000),
                           aes(label = paste(ap, "x", bp)),
                           nudge_x = 250,
                           segment.alpha = .4) +
  coord_cartesian(xlim = c(0, 1350)) +
  scale_y_continuous(breaks = c(.92, .93, .94, .95, .96, .97, .98))
p3 = gridExtra::grid.arrange(p1,p2, ncol = 1)
ggsave("figures/sim_fig_ci.pdf",
       plot = p3, 
       width = 10, height = 9, units = "in")
```

The Monte Carlo simulation produced 45,000 marginal mediation models (although including the bootstrapped intervals there were 22.5 million models run). These simulated models were run on powerful Core i7 computers over the span of several days. The following subsections discuss the results of the simulations in regard to each outcome of interest.


### Decomposed Total Effect Equals The Total Effect

One of the major questions about the performance of MMA regards whether the decomposed total effect equals the total effect ($a \times b + c' = c$). Table \ref{tab_discrep} highlights the average discrepancy between the decomposed total effect and the total effect divided by the total effect (thereby adjusting the discrepancy for the size of the total effect). Clearly, on an average level, deviations are extremely small, generally < .5\% discrepancy, with the majority < .1\% discrepancy. The discrepancies also decrease in size as the sample size increases.

```{r sim_total_tab, eval=FALSE}
total_total %>%
  group_by(dist, sample) %>%
  summarize(tot1 = mean(total),
            tot2 = mean(indirect + direct),
            true = mean(true)) %>%
  mutate(est = (tot1 - tot2) / tot1) %>%
  mutate(est2 = tot1 - tot2) %>%
  data.table::dcast(sample~dist, value.var = "est") %>%
  xtable::xtable(digits = 4) %>%
  xtable::print.xtable(include.rownames = FALSE)
```

\begin{table}[ht]
\centering
\caption{Average discrepancies between the decomposed total effect and the total effect for various sample sizes.}
\begin{tabular}{lcc}
\toprule
  & \multicolumn{2}{c}{Mediator} \\
Sample Size & Binary & Count \\ 
\midrule
  50   & 0.0017  & -0.0080 \\ 
  100  & 0.0024  & -0.0028 \\ 
  200  & 0.0007  &  0.0027 \\ 
  500  & 0.0001  & -0.0036 \\ 
  1000 & -0.0000 & -0.0027 \\ 
\bottomrule
\end{tabular}\label{tab_discrep}
\end{table}

Figure \ref{fig:totaltotal} presents the individual simulated differences between the decomposed total effect and the total effect. Once assessing the individual discrepancies, two patterns are of note:

1. There are larger discrepancies for smaller sample sizes and larger effect sizes.
2. Besides a single outlier in the count condition (Panel b), most discrepancies are small.

First, the largest discrepancies are where the sample sizes are small (n = 50) and the effect sizes are larger. This is intuitive in that as the effect size is larger, the amount of discrepancy that is still considered small also increases (i.e., variability simply due to the estimates being on a larger scale). For both binary and count mediators, the discrepancies, even in the large effect sizes, are very small as the sample increases to n = 1000. Given the literature review, this is a sample size that is often possible in the health and prevention sciences. Further, most effect sizes in the literature were moderate or smaller. These conditions had low variability in the discrepancy.

Second, in the count condition there is a clear outlying value (>2 for the n = 50 and large/large effect size condition). Other than this value---across the binary and count mediators---all other values are relatively close to zero. For the binary mediator condition, the scale was in risk (probability) units. The discrepancies, here, in the n = 50 condition are notable in their size while the other conditions had discrepancies that are essentially within rounding error. For the count mediator condition, the scale of the total effect was in count units. The outlier is notable in its large discrepancy in these units; most other values were essentially within rounding error of the effect size.

\begin{figure}[tb]
\centering
\includegraphics[width = \linewidth]{figures/fig_total_total.pdf}
\caption{The simulated differences between the decomposed total effect and the total effect. The discrepancies are higher for smaller sample sizes and larger effect sizes.}
\label{fig:totaltotal}
\end{figure}

Ultimately, this provides evidence of MMAs ability to estimate values that let the $a \times b + c' = c$ condition to hold, even in individual applications. This, however, is somewhat dependent on the sample size. As for differences across the effect sizes of the a and b paths, as an effect size increases so does the level of "rounding error." That is, in large effects, larger discrepancies are still a minor deviation than if the effect was small. Therefore, the main aspect of this finding is that sample size is important in the accuracy of the indirect plus direct equaling the total effect.

### Statistical Power

Figure \ref{fig_power} shows the statistical power of MMA across the various conditions. The figure shows the statistical power at each tested sample size for each combination of effect sizes (e.g., "Mod x Large" is a moderate a path effect size and a large b path effect size). Overall, most effect size combinations are adequately powered at a sample size of 200 across both binary and count mediator conditions. Interestingly, the "Small x Small" condition had more power at higher sample sizes than "Large x Small", which is contrary to intuition. However, the issue here was the issue of _complete separability_ wherein the estimates and the standard errors are either biased or not estimable in logistic regression. With a large effect and a large sample size, this became common, thus reducing the statistical power in these conditions. The count mediator condition did not have this issue.

\begin{figure}[tb]
\centering
\includegraphics[width = \linewidth]{figures/sim_fig_power.pdf}
\caption{The simulated levels of power per tested sample size (x-axis) and effect size of the indirect path (color; a combination of the a path by the b path) stratified by the distribution of the mediator (binary or count).}
\label{fig_power}
\end{figure}

Overall, the method has the statistical power for even very small indirect effects with a sample size of 1000. As mentioned before, sample sizes greater than 1000 are common in the literature suggesting the method can be used even to detect small effect sizes.

### Estimation Accuracy

It is also important for MMA to estimate the expected parameters. Figure \ref{fig_acc} highlights that MMA is consistent in estimating the underlying effects for each combination of effect sizes across the various sample sizes. In the figure, which is stratified by the combination of effect sizes, shows the population parameter (vertical lines) and the estimated values (the density distributions). Overall, the distributions are centered at the true population parameter in each situation across the conditions.

\begin{figure}[tb]
\centering
\includegraphics[width = \linewidth]{figures/sim_fig_acc.pdf}
\caption{The simulated accuracy per tested sample size (x-axis) and effect size of the indirect path (color; a combination of the a path by the b path).}
\label{fig_acc}
\end{figure}

As also seen in Figure \ref{fig:totaltotal}, there is more variability in the estimation for larger effect sizes than for smaller. Again, this variability is likely due to the estimates being on a larger scale.


### Confidence Interval Coverage

Finally, the confidence interval coverage is shown in Figure \ref{fig_ci}. Panel a) of the figure shows the overview---that the confidence interval coverage is around the 95\% line for both the binary and count mediator conditions. However, looking at it much more closely in Panel b) it is clear that there is some deviation from the 95\% line, particularly in the binary mediator condition. This is not a major deviation but an important one, nonetheless. Given the use of the percentile bootstrapping method herein, it may be important to apply other bootstrapping approaches such as the Bias-Corrected Bootstrap.

\begin{figure}[tb]
\centering
\includegraphics[width = \linewidth]{figures/sim_fig_ci.pdf}
\caption{The simulated confidence interval coverage per tested sample size (x-axis) and effect size of the indirect effect . The "ideal" level is set at 0.95. Panel a) shows that the confidence intervals from a broad perspective. Panel b) provides a closer look at the individual patterns of the confidence intervals around the ideal level of 0.95.}
\label{fig_ci}
\end{figure}

This finding of the indirect effect having confidence intervals that were too narrow has been found previously for the percentile bootstrapped [as applied in MMA; @MacKinnon2004]. However, @MacKinnon2004 also found the bootstrap methods, including the percentile approach, is among the best of the tested approaches. Other approaches, including the Monte Carlo confidence interval can be tested in future studies.


# Conclusion

Marginal Mediation Analysis shows promise in its ability to accurately estimate models wherein the mediator is a binary or a count variable. Results regarding the decomposed total effect equaling the total effect are positive, although the estimation accuracy of this relationship depends on the sample and effect sizes. The statistical power is comparable to other modern mediation techniques wherein even small effect sizes can be estimated with a sample size of 1000. The estimation is consistent, ultimately averaging at the true population value. The confidence interval coverage was often too narrow for the binary mediator condition---sometimes having coverage of just above 92\%---but it was approximately correct for the count mediator condition with some variability around 95\%. Finally, the software for MMA is free to use in the R statistical environment in the `MarginalMediation` package. This allows researchers to begin to use the approach with little overhead. All in all, MMA appears to be a practical approach to difficult mediation situations.




\singlespacing